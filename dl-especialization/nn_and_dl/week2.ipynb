{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "\n",
    "## Binary classification\n",
    "\n",
    "## Logistic regression\n",
    "\n",
    "$\\hat{y} = \\sigma(w^Tx+b)$\n",
    "\n",
    "where the sigmoid function is $\\sigma(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "$w$ is an $n_x$ dimensional vector, and $b$ is a real number\n",
    "\n",
    "## Logistic regression cost function\n",
    "\n",
    "The loss (error) function: $L(\\hat{y},y) = \\frac{1}{2}(\\hat{y}-y)^2$\n",
    "\n",
    "$L(\\hat{y}-y) = -(ylog\\hat{y} + (1-y)log(1-\\hat{y}))$\n",
    "\n",
    "Cost funcion: $J(w,b) = -\\frac{1}{n} \\sum^n_{i=1}[y^{(i)}log\\hat{y}^{(i)}+(1-y^{(i)})log(1-\\hat{y}^{(i)})]$\n",
    "\n",
    "- The **loss function** computes the error for a single training example, while the **cost function** is the average of the loss functions of the entire training set.\n",
    "\n",
    "## Gradient Descent\n",
    "* Want to find $w, b$ that minimize $J(w,b)$\n",
    "\n",
    "$w := w - \\alpha \\frac{dJ(w)}{dw}$\n",
    "\n",
    "Where $\\alpha$ is the learn rate and controls the steps we take on each iteragion or gradient descent, while the derivative term represents the slope of the function.\n",
    "\n",
    "$J(w,b) = \\frac{1}{m} \\sum^m_{i=1} L(\\hat{y}^{(i)}, y^{(i)} = -\\frac{1}{m}\\sum^m_{i=1}(y^{(i)}log\\hat{y}^{(i)} + (1-y^{(i)})log(1-\\hat{y}^{(i)}))$\n",
    "\n",
    "## Derivatives\n",
    "\n",
    "* On a straight line, the function's derivative doesn't change.\n",
    "\n",
    "* The slope of the function can be different to different points in the function\n",
    "\n",
    "## Computation graph\n",
    "\n",
    "* It's the left-right calculation direction of **foward propagation**\n",
    "* One step of **backward propagation** on a computation graph yields derivative of final output.\n",
    "\n",
    "## Derivatives with a computation graph\n",
    "\n",
    "## Logistic regression gradient descent\n",
    "\n",
    "## Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3,4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249997.58501630303\n",
      "Vectorization version: 1.4030933380126953 ms\n",
      "249997.58501630262\n",
      "For loop: 619.0812587738037 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print(c)\n",
    "print(\"Vectorization version: \" + str(1000*(toc-tic)) + \" ms\")\n",
    "\n",
    "c = 0\n",
    "tic = time.time()\n",
    "for i in range(1000000):\n",
    "    c += a[i] * b[i]\n",
    "toc = time.time()\n",
    "\n",
    "print(c)\n",
    "print(\"For loop: \" + str(1000*(toc-tic)) + \" ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 2 µs, total: 4 µs\n",
      "Wall time: 5.96 µs\n",
      "249995.94173242358\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "c = np.dot(a,b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 6.2 µs\n",
      "249995.94173242492\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "c = 0\n",
    "tic = time.time()\n",
    "for i in range(1000000):\n",
    "    c += a[i] * b[i]\n",
    "    \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
