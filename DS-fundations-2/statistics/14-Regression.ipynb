{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "## Machine learning\n",
    "\n",
    "### 1. Supervised learning\n",
    "Where we use input data to predict a label for that data\n",
    "* Using credit card transaction data to predict fraudulent transactions;\n",
    "* Using customer financial data to predict the chance of a default on a loan;\n",
    "* Using neighborhood characteristics to predict home prices.\n",
    "\n",
    "**Linear and logistic regression fall into here.**\n",
    "\n",
    "### 2. Unsupervised learning\n",
    "Clustering together data based on common characteristics (these data don't have labels like in supervised ML techniques)\n",
    "* Trying to group similar customer segments;\n",
    "* Group documents that cover similar topics.\n",
    "---\n",
    "\n",
    "## Linear regression introduction\n",
    "\n",
    "### a) Simple linear regression\n",
    "The most simple form of regression. A linear comparison of only two quantitative variables.\n",
    "* *Prices* x **sales**;\n",
    "* *Temperature* x **humidity**;\n",
    "* *Height* x **weight**;\n",
    "* *Hours studying* x **test grade**.\n",
    "\n",
    "A common way to visualize these relationships is with a scatter plot. The variable on the $Y$ axis is called *the response* or *dependent*, where the variable on the $X$ axis is called *explanatory* or *independent*\n",
    "* $Response$ $variable$ $(Y):$ the variable we're interested in predict;\n",
    "* $Explanatory$ $variable$ $(X):$ the variable used to predict the response.\n",
    "\n",
    "The **scatter plot** can be used to visualize both the strength and the direction of the relationship between two variables.\n",
    "* Positive relation: when both variables increases.\n",
    "* Negative relation: when one variable increases and the other decreases.\n",
    "* As the points spread out from one another this weakens the relationship.\n",
    "* To identify strong or weak relationships, we aren't so much looking at the slope associated with the relationship.\n",
    "* Generally, we consider strength as either weak, moderate or strong. And direction as positive or negative.\n",
    "\n",
    "[$Correlation$ $coeficient$ $of$ $Pearson$ $(r)$](https://pt.wikipedia.org/wiki/Coeficiente_de_correla%C3%A7%C3%A3o_de_Pearson) is the strength and direction of a linear relationship, always between -1 and 1, where the closer it is to 1 or -1, the stronger the relationship. Negative values indicate negative relationship, otherwise positive relationship.\n",
    "\n",
    "**Ps.:** [Spearman coeficient](https://pt.wikipedia.org/wiki/Coeficiente_de_correla%C3%A7%C3%A3o_de_postos_de_Spearman) is[ more indicated for specific cases with two variables (more options](https://pt.wikipedia.org/wiki/Coeficiente_de_correla%C3%A7%C3%A3o_de_postos_de_Spearman)).\n",
    "\n",
    "---\n",
    "\n",
    "## Correlation coeficients\n",
    "There is some rules, but this is a highly field-dependent measure.\n",
    "* **Strong relationship:** 0.7 <= |r| < 1;\n",
    "* **Moderate relationship:** 0.3 <= |r| < 0.7;\n",
    "* **Weak relationship:** 0.0 <= |r| < 0.3.\n",
    "\n",
    "**Ps.:** Negative correlation coeficient don't indicate a weak relationship.\n",
    "\n",
    "**Ps2.:** On excel the function is `CORREL(col1, col2)` ([example](https://docs.google.com/spreadsheets/d/1bZs0QjX0d_TKeLcbBZKwLq9mCE5Gpgq0XrliVeq_FZg/edit#gid=0))\n",
    "\n",
    "---\n",
    "\n",
    "## What defines a line?\n",
    "We define it by two values, an intercept and a slope.\n",
    "* **Intercept** tells us the predicted value of the response when the explanatory variable is zero. Commonly used for the population and sample intercept values, pronouced  beta knot for the parameter and B0 for statistic.\n",
    "* **Slope ($beta1$)** tells us the predicted change in the response for each additional one unit increase in the explanatory variable ($X$). For parameter is beta one and b1 for the statistic\n",
    "\n",
    "Once we've fit a line to these points, we define with this equation\n",
    "\n",
    "$ŷ$ $=$ $b0$ $+$ $b1x$\n",
    "\n",
    "* $b0$ is where the x value is equal to zero;\n",
    "* $b1$ is the change along the y-axis in the line;\n",
    "* $ŷ$ define the values that we get from the fitted line (predicted result);\n",
    "* $y$ defines the actual data points (actualresult);\n",
    "\n",
    "\n",
    "Values out of the line are define line e $(x1,y1)$, but values in the line are define positions like $(x1,ŷ1)$\n",
    "\n",
    "---\n",
    "\n",
    "## Fitting a regression line\n",
    "In bi-variate case, we're interested in fiding a line that best allows us to predict the response variable (y) using the explanatory variable (x).\n",
    "The main algorith used to find the best line is  the **least squares regression algorithm** and the way the line is chosen is by minimizing the sum of squared vertical distances between our fitted line and each of these points\n",
    "To calculate the difference between the point and the arrow: $y1$ $-$ $ŷ1$.\n",
    "For each of the data points in the data set, look at the distance between the predicted and actual values, square these, and them sum them all together.\n",
    "\n",
    "$\\sum_{i=1}^{x}$ $(yi$ $-$ $ŷi)^2$\n",
    "\n",
    "And if our line creates a smaller value than for any other line, then this is the line we want to use.\n",
    "\n",
    "* [Another video about linear regressionan analysis intro](https://www.youtube.com/watch?v=zPG4NjIkCjc)\n",
    "\n",
    "To calculate the intercept we need to known:\n",
    "\n",
    "$\\bar{x}$ $=$ $\\frac{1}{n}$ $\\sum$ $x_i$\n",
    "\n",
    "$\\bar{y}$ $=$ $\\frac{1}{n}$ $\\sum$ $y_i$\n",
    "\n",
    "$s_y$ $=$ $\\sqrt{\\frac{1}{n=1}\\sum(y_i-\\bar{y})²}$\n",
    "\n",
    "$s_x$ $=$ $\\sqrt{\\frac{1}{n=1}\\sum(x_i-\\bar{x})²}$\n",
    "\n",
    "$r$ $=$ $\\frac{\\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})²}{\\sqrt{\\sum(y_i-\\bar{y})^2}}}$\n",
    "\n",
    "$b_1$ $=$ $r_\\frac{s_y}{s_x}$\n",
    "\n",
    "$b_0$ $=$ $\\bar{y}-b_1\\bar{x}$\n",
    "\n",
    "## Fitting a regression line in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>598291</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1744259</td>\n",
       "      <td>3512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>571669</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>493675</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101539</td>\n",
       "      <td>2208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price  area\n",
       "0   598291  1188\n",
       "1  1744259  3512\n",
       "2   571669  1134\n",
       "3   493675  1940\n",
       "4  1101539  2208"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('house_price_area_only.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>598291</td>\n",
       "      <td>1188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1744259</td>\n",
       "      <td>3512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>571669</td>\n",
       "      <td>1134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>493675</td>\n",
       "      <td>1940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101539</td>\n",
       "      <td>2208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price  area  intercept\n",
       "0   598291  1188          1\n",
       "1  1744259  3512          1\n",
       "2   571669  1134          1\n",
       "3   493675  1940          1\n",
       "4  1101539  2208          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column to intercept result, statsmodels doesn't do this\n",
    "df['intercept'] = 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are only rare cases where add intercept is not necessary ([link discussion](https://stats.stackexchange.com/questions/7948/when-is-it-ok-to-remove-the-intercept-in-a-linear-regression-model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.678</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.678</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.269e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 14 Jan 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:34:42</td>     <th>  Log-Likelihood:    </th> <td> -84517.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6028</td>      <th>  AIC:               </th> <td>1.690e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6026</td>      <th>  BIC:               </th> <td>1.691e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td> 9587.8878</td> <td> 7637.479</td> <td>    1.255</td> <td> 0.209</td> <td>-5384.303</td> <td> 2.46e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>area</th>      <td>  348.4664</td> <td>    3.093</td> <td>  112.662</td> <td> 0.000</td> <td>  342.403</td> <td>  354.530</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>368.609</td> <th>  Durbin-Watson:     </th> <td>   2.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 349.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.534</td>  <th>  Prob(JB):          </th> <td>1.43e-76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.499</td>  <th>  Cond. No.          </th> <td>4.93e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.93e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.678\n",
       "Model:                            OLS   Adj. R-squared:                  0.678\n",
       "Method:                 Least Squares   F-statistic:                 1.269e+04\n",
       "Date:                Mon, 14 Jan 2019   Prob (F-statistic):               0.00\n",
       "Time:                        20:34:42   Log-Likelihood:                -84517.\n",
       "No. Observations:                6028   AIC:                         1.690e+05\n",
       "Df Residuals:                    6026   BIC:                         1.691e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept   9587.8878   7637.479      1.255      0.209   -5384.303    2.46e+04\n",
       "area         348.4664      3.093    112.662      0.000     342.403     354.530\n",
       "==============================================================================\n",
       "Omnibus:                      368.609   Durbin-Watson:                   2.007\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              349.279\n",
       "Skew:                           0.534   Prob(JB):                     1.43e-76\n",
       "Kurtosis:                       2.499   Cond. No.                     4.93e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.93e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provide to OLS method the Y and X variables\n",
    "lm = sm.OLS(df['price'], df[['intercept', 'area']])\n",
    "# Fit the model\n",
    "results = lm.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
