{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous supervised learning\n",
    "We worked with **discrete** outputs (1 or 0, fast or slow, binary outputs), now let's see continuous outputs.\n",
    "\n",
    "Make an output continuous implies that there's some sort of an ordering to it;\n",
    "\n",
    "A way to write a result of a supervised learned is by  the regression linear equation\n",
    "\n",
    "y = 500 (slope)\n",
    "x = 80\n",
    "net worth = 500/80 * age + 0 (age is 0 the net worth is zero)\n",
    "net worth = 6.25 * age\n",
    "\n",
    "in general:\n",
    "target = slope * input + intercept\n",
    "\n",
    "##  Slope and intercept\n",
    "$y=m*x+\\beta$\n",
    "\n",
    "$m$ is slope that is y/x\n",
    "$\\beta$ is the intercept that is the $y$ value when x is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=36\n",
    "y = (6.25*x) + 0\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (6.25*x) + 30\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn linear regression\n",
    "\n",
    "* [Generalized Linear Models](https://scikit-learn.org/stable/modules/linear_model.html)\n",
    "* [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)\n",
    "* The `.predict()` function expect a list of values;\n",
    "* We can see the slope (`.coef_`) and intercept (`.intercept_`);\n",
    "* The R-square score can be calculated by `.score()` function in the test and train data to know the performance.\n",
    "* The R-square maximum value is 1, so more near 1 it's better is;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(ages_train, net_worths_train)\n",
    "\n",
    "### get Katie's net worth (she's 27)\n",
    "### sklearn predictions are returned in an array, so you'll want to index into\n",
    "### the output to get what you want, e.g. net_worth = predict([[27]])[0][0] (not\n",
    "### exact syntax, the point is the [0] at the end). In addition, make sure the\n",
    "### argument to your prediction function is in the expected format - if you get\n",
    "### a warning about needing a 2d array for your data, a list of lists will be\n",
    "### interpreted by sklearn as such (e.g. [[27]]).\n",
    "km_net_worth = reg.predict([[27]])[0][0] ### fill in the line of code to get the right value\n",
    "\n",
    "### get the slope\n",
    "### again, you'll get a 2-D array, so stick the [0][0] at the end\n",
    "slope = reg.coef_[0][0] ### fill in the line of code to get the right value\n",
    "\n",
    "### get the intercept\n",
    "### here you get a 1-D array, so stick [0] on the end to access\n",
    "### the info we want\n",
    "intercept = reg.intercept_[0] ### fill in the line of code to get the right value\n",
    "\n",
    "\n",
    "### get the score on test data\n",
    "test_score = reg.score(ages_test, net_worths_test) ### fill in the line of code to get the right value\n",
    "\n",
    "\n",
    "### get the score on the training data\n",
    "training_score = reg.score(ages_train, net_worths_train) ### fill in the line of code to get the right value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression linear errors\n",
    "\n",
    "error = actual net worth - predicted net worth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18.75"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = 35\n",
    "p_nw = 218.75\n",
    "a_nw = 200\n",
    "err = a_nw - p_nw\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimizing the sum of squared errors\n",
    "\n",
    "The best regression is the one that minimizes the $\\sum$ of all training points.\n",
    "$\\sum(actual-predicted)^2$\n",
    "\n",
    "actual is the training points\n",
    "predicted is the predictions from regression ($y=m*x+\\beta$)\n",
    "\n",
    "* **ordinary least squares (OLS)** used by sklearn LinearRegression\n",
    "* **gradient descent**\n",
    "\n",
    "## What regreession line looks \"best\"?\n",
    "\n",
    "* Look for the margins;\n",
    "* There can be multiple lines that minimize $\\sum|error|$, but only one line will minimize $\\sum{error}^2$;\n",
    "* Using the SSE (sum of the square error) also makes implementation much easier;\n",
    "* SSE isn't perfect, as an evaluation metric. As you add more data the sum of the squared error will almost certainly go up, but it doesn't necessarily mean that your fit is doing worse job.\n",
    "\n",
    "## R-squared ($r^2$) of a regression\n",
    "\n",
    "Is a very popular evaluation metric for describing the goodness of fit of a linear regression.\n",
    "\n",
    "How much of my change in the output ($y$) is explained by the change in my input ($x$)?\n",
    "\n",
    "$0<r^2<1$\n",
    "\n",
    "If the number is very small (near 0), generally means that the regression line isn't doing a good job of capturing the trend in the data. If is near 1, the regression line is good describing the relationship between the input ($x$) and the output ($y$).\n",
    "\n",
    "It is independent of the number of training points, been more reliable than a sum of square errors.\n",
    "\n",
    "With more features is possible to push up the r-squared value\n",
    "\n",
    "## Visualize the regression\n",
    "\n",
    "Use scatter plot\n",
    "\n",
    "## Comparing classification and regression\n",
    "\n",
    "| property                     | supervised classification | regression                          |\n",
    "|------------------------------|---------------------------|-------------------------------------|\n",
    "| output type                  | discrete (class labels)   | continuous (number)                 |\n",
    "| what are you trying to find? | decision boundary         | \"best fit line\"                     |\n",
    "| evaluation                   | accuracy                  | \"sum of squared error\" or r-squared |\n",
    "\n",
    "## Multi-variate regression\n",
    "\n",
    "## Running script\n",
    "\n",
    "Input salary to predict the bonus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
