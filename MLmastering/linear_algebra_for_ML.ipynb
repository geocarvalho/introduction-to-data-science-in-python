{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear-algebra-for-ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOH/8YK3FXRc7Ak17NUnIgj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geocarvalho/python-ds/blob/master/MLmastering/linear_algebra_for_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlxjWRKAWST3",
        "colab_type": "text"
      },
      "source": [
        "# [Basics for linear algebra for ML - Discover the mathematical language of data in python - Jason Bownlee](https://machinelearningmastery.com/linear_algebra_for_machine_learning/)\n",
        "\n",
        "## Chapter 4 - Introduction to Numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPOvqeDEWGgK",
        "colab_type": "code",
        "outputId": "c8bc3c5e-992c-4425-db4a-e0e30a0d5e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create array\n",
        "l = [1.0, 2.0, 3.0]x\n",
        "a = np.array(l)\n",
        "\n",
        "# Display array\n",
        "print(a)\n",
        "\n",
        "# Display array shape\n",
        "print(a.shape)\n",
        "\n",
        "# Display array data type\n",
        "print(a.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 2. 3.]\n",
            "(3,)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FGAmpaLc3sF",
        "colab_type": "text"
      },
      "source": [
        "### Creating arrays\n",
        "\n",
        "* An empty array with aleatory numbers with `empty()`;\n",
        "* An array with zeros using `zeros()`;\n",
        "* An array with ones using `ones()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_aKKXW1ACgT",
        "colab_type": "code",
        "outputId": "f36b10eb-95ce-44b4-d64c-ce03a50a5755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Create empty array\n",
        "a = np.empty([3,3])\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.84564651e-316 2.07507571e-322 2.12199579e-314]\n",
            " [3.44620186e-085 4.34900767e+199 1.87422380e+261]\n",
            " [1.43622020e+161 3.27748089e+180 1.27014396e-319]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztIz4BN5AnVp",
        "colab_type": "code",
        "outputId": "e5c62bbf-77a3-42b5-ce95-8f0ce4514f05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Create zero array\n",
        "a = np.zeros([3, 5])\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSdNozJgA4py",
        "colab_type": "code",
        "outputId": "7a2e15a7-67ff-4b76-cff3-d0eaa623c8d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Create one array\n",
        "a = np.ones([2,5])\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odLJmY-6c6OT",
        "colab_type": "text"
      },
      "source": [
        "### Combining arrays\n",
        "\n",
        "* Vertical Stack with `vstack()`\n",
        "* Horizontal Stack with `hstack()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWQ0VBKmBCHy",
        "colab_type": "code",
        "outputId": "d22d5e24-adb0-4b13-937f-de388ad4b40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a1 = np.array([1,2,3])\n",
        "a2 = np.array([4,5,6])\n",
        "print(a1)\n",
        "print(a2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 3]\n",
            "[4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgIfXI7yeAFq",
        "colab_type": "code",
        "outputId": "4e18bc52-d627-466a-c3cb-0cd4ba2e2108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "a3 = np.vstack((a1, a2))\n",
        "print(a3)\n",
        "print(a3.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "(2, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZa6mY_wdW1U",
        "colab_type": "code",
        "outputId": "c32ee478-f9f8-4ee8-d3f2-acf61ec16502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a4 = np.hstack((a1, a2))\n",
        "print(a4)\n",
        "print(a4.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 3 4 5 6]\n",
            "(6,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfcjj6CPeWo5",
        "colab_type": "text"
      },
      "source": [
        "## Chapter 5 - Index, slice and reshape Numpy arrays\n",
        "\n",
        "### From list to arrays\n",
        "\n",
        "* One-dimensional list to array\n",
        "* Two-dimensional list of lists to array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBP81cLoeFml",
        "colab_type": "code",
        "outputId": "9ec9da7f-878c-452d-f7d3-397304a44f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create one-dimensional array\n",
        "data1 = [11, 22, 33, 44, 55]\n",
        "\n",
        "# Array of data\n",
        "data1 = np.array(data1)\n",
        "data1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11, 22, 33, 44, 55])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF_UTmfkfx1x",
        "colab_type": "code",
        "outputId": "c8357944-a224-421f-ebb5-f5468b7c0b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Create two-dimensional array\n",
        "data2 = [[11, 22],\n",
        "        [33, 44],\n",
        "        [55, 66]]\n",
        "\n",
        "# Array of data\n",
        "data2 = np.array(data2)\n",
        "data2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11, 22],\n",
              "       [33, 44],\n",
              "       [55, 66]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3KtCyZIgJ6t",
        "colab_type": "text"
      },
      "source": [
        "### Array indexing\n",
        "* One-dimensional indexing\n",
        "* Two-dimensional indexing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwm-4EVCgFPy",
        "colab_type": "code",
        "outputId": "947261ac-ab98-47d5-e91b-6cc47bc28ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# One-dimensional\n",
        "print(data1[0])\n",
        "print(data1[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n",
            "55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-DIL5v5gzxj",
        "colab_type": "code",
        "outputId": "6e983a97-c46c-4a27-9a48-154fb3f45701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Two dimensional\n",
        "print(data2[0,0])\n",
        "print(data2[0,])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n",
            "[11 22]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx7MiC_RgxWv",
        "colab_type": "code",
        "outputId": "fc8ffcfb-6e9e-4352-e5d3-7ccae170f399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Two dimensional like C-based languages\n",
        "print(data2[0])\n",
        "print(data2[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11 22]\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmIxTDZ7hQq6",
        "colab_type": "text"
      },
      "source": [
        "### Array slicing\n",
        "* One-dimensional slicing\n",
        "* Two-dimensional slicing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5njuSaYhIjm",
        "colab_type": "code",
        "outputId": "85fcb372-cd94-46ff-c4f2-2c7a642da372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# One-dimensional\n",
        "print(data1[:])\n",
        "print(data1[0:1])\n",
        "print(data1[-2:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11 22 33 44 55]\n",
            "[11]\n",
            "[44 55]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoVQQHsbhs-p",
        "colab_type": "code",
        "outputId": "4a4f4ad2-51e6-4dcc-99bb-f6eacea67fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Two-dimensional\n",
        "print(data2[:, :-1])\n",
        "print(data2[:, -1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11]\n",
            " [33]\n",
            " [55]]\n",
            "[22 44 66]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSUhSPriiZkZ",
        "colab_type": "code",
        "outputId": "8b7b84f9-f988-4d70-d2f9-b2cb4a64f811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "data = np.array([\n",
        "[11, 22, 33],\n",
        "[44, 55, 66],\n",
        "[77, 88, 99]])\n",
        "\n",
        "print(data[:, :-1])\n",
        "print(data[:, -1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11 22]\n",
            " [44 55]\n",
            " [77 88]]\n",
            "[33 66 99]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udBodaKm0cmC",
        "colab_type": "text"
      },
      "source": [
        "### Array reshaping\n",
        "* Reshape 1d to 2d array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DVK8lTj1FgV",
        "colab_type": "code",
        "outputId": "8b84e7e3-3f3e-48db-9dc5-d811c47f67d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDQPrcad1IUa",
        "colab_type": "code",
        "outputId": "af2b2a26-21f0-45a9-82ea-73827786dd56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUcoWwdd1TbN",
        "colab_type": "code",
        "outputId": "9e468c10-e9c9-45ac-ca55-86964b0973a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print( ' Rows: %d ' % data2.shape[0])\n",
        "print( ' Cols: %d ' % data2.shape[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Rows: 3 \n",
            " Cols: 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bciqpf3x1c02",
        "colab_type": "code",
        "outputId": "3d8111cf-c133-4e2b-fd04-2970d2ca392c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# reshape 1D to 2D array\n",
        "data = data1.reshape((data1.shape[0], 1))\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IApFbLF14gG",
        "colab_type": "code",
        "outputId": "1d141495-ea43-4e41-f18e-5cf902f16f87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "data = data2.reshape((data2.shape[0], data2.shape[1], 1))\n",
        "print(data)\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[11]\n",
            "  [22]]\n",
            "\n",
            " [[33]\n",
            "  [44]]\n",
            "\n",
            " [[55]\n",
            "  [66]]]\n",
            "(3, 2, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qf5vOxw2nPL",
        "colab_type": "text"
      },
      "source": [
        "## Chapter 6 - Numpy array broadcasting\n",
        "\n",
        "* Duplicate the smaller array so that it has the dimensionality and size as the larger array.\n",
        "\n",
        "### Limitation with array arithmetic\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD2GPzcP2V2c",
        "colab_type": "code",
        "outputId": "fe9ecefa-8685-421f-a30a-4d8268652cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = np.array([1, 2, 3])\n",
        "b = np.array([1, 2, 3])\n",
        "c = a + b\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 4, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSKRGaiaVRpC",
        "colab_type": "text"
      },
      "source": [
        "### Broadcast scalar to one-dimensional array\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5IhccxrVP49",
        "colab_type": "code",
        "outputId": "4c8b2a33-8735-459d-daaf-8407c16504dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = np.array([1, 2, 3])\n",
        "b = 2\n",
        "c = a + b\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T86K6K-gWuEV",
        "colab_type": "text"
      },
      "source": [
        "### Broadcast scalar to two-dimensional array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwbfDPI4WotW",
        "colab_type": "code",
        "outputId": "3dfab5cc-6b5e-49d1-c856-4539ed715c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a = np.array([\n",
        "[1, 2, 3],\n",
        "[1, 2, 3]])\n",
        "b = 2\n",
        "c = a + b\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 4, 5],\n",
              "       [3, 4, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-LtLWfKXBA5",
        "colab_type": "text"
      },
      "source": [
        "### One-dimensional and two-dimensional arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEetWSJ0W_wJ",
        "colab_type": "code",
        "outputId": "e00771c1-df79-41cd-bead-77ad6f3725d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a = np.array([\n",
        "[1, 2, 3],\n",
        "[1, 2, 3]])\n",
        "b = np.array([1,2,3])\n",
        "c = a + b\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 4, 6],\n",
              "       [2, 4, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME1VAdOzXi2X",
        "colab_type": "text"
      },
      "source": [
        "### Limitations\n",
        "\n",
        "* Arithmetic, including broadcasting, can only be performed when the shape of each dimension in the arrays are equal or one has the dimension size of 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OFEZ5aqWj2Q",
        "colab_type": "code",
        "outputId": "9f1cba8c-820a-4d6c-c5b6-c68c80884d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "a = np.array([\n",
        "[1, 2, 3],\n",
        "[1, 2, 3]])\n",
        "print(a.shape)\n",
        "b = np.array([1,2])\n",
        "print(b.shape)\n",
        "c = a + b\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 3)\n",
            "(2,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-40e8d200a87a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (2,) "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovbqmca-YOz9",
        "colab_type": "text"
      },
      "source": [
        "## Chapter 7 - Vectors and vector arithmetic\n",
        "\n",
        "* Vector is a tuple of one or more values called scalars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO-37hKLX4px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = np.array([1,2,3])\n",
        "v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZlAcbr6bMS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([1,2,3])\n",
        "b = np.array([1,2,3])\n",
        "c = a + b\n",
        "c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ai58fFybWcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = a - b\n",
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-853333bb8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e = a * b\n",
        "e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw1r_ekMbfAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = a / b\n",
        "f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtf3fBeJbyfl",
        "colab_type": "text"
      },
      "source": [
        "### Vector dot product\n",
        "\n",
        "* The sum of the multiplied elements of two vectors of the same length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1uV3vnobut0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = a.dot(b)\n",
        "g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjdsmJ8echb6",
        "colab_type": "text"
      },
      "source": [
        "### Vector-scalar multiplication\n",
        "\n",
        "* Multiply each element of the vector by a scalar, resulting in a new scaled vector of the same length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z9C-CwqcFb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = 0.5\n",
        "s * a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQeRRKkSf_a_",
        "colab_type": "text"
      },
      "source": [
        "## Chapter 8 - Vector Norms\n",
        "\n",
        "* Vector norm is the calculation of vector lengths or magnitudes;\n",
        "\n",
        "* $L^1$ norm is the sum of the absolute values of the vector;\n",
        "\n",
        "* $L^2$ norm is the square root of the sum of the squared vector values;\n",
        "\n",
        "* The $max$ norm is the maximum vector values.\n",
        "\n",
        "\n",
        "### Vector norm (magnitude)\n",
        "\n",
        "* The length of the vector is always a positive number, except for a vector of zeros as values;\n",
        "\n",
        "* It's calculated using some measure that summarizes the distance of the vector from the origin of the vector space.\n",
        "\n",
        "### Vector $L¹$ norm\n",
        "\n",
        "* The notation of a vector is $||v||_1$, where 1 is a subcript;\n",
        "\n",
        "* This length is sometimes called **the taxicab norm** or **the Manhattan norm**;\n",
        "\n",
        "$L^1(v) = ||v||_1$\n",
        "\n",
        "* It's calculated as the sum of the absolute vector values, where the absolute value of a scalar uses the notation $|a_1|$;\n",
        "\n",
        "* The norm is a calculation of the Manhattan distance from the origin of the vector space\n",
        "\n",
        "$||v||_1 = |a_1| + |a_2| + |a_3|$\n",
        "\n",
        "* It can be calculated in Numpy using the `norm()` function with a paramater to specify the norm order (1 in this case)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyy9CjAGcewe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([1, 2, 3])\n",
        "l1 = np.linalg.norm(a, 1)\n",
        "l1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEYHF2M1plTm",
        "colab_type": "text"
      },
      "source": [
        "> The $L^1$ norm is often used when fitting ML algorithms as a regularization method. For example, a method to keep the coefficients of the model small and in turn, the model less complex.\n",
        "\n",
        "### Vector $L^2$ norm\n",
        "\n",
        "* The notation is $||v||_2$, where 2 is a subscript\n",
        "\n",
        "$L^2(v) = ||v||_2$\n",
        "\n",
        "* It calculates the distance of the vector coordinate from the origin of the vector space. Also know as **the Euclidean norm** as it's calculated as the Euclidean distance from the origin;\n",
        "\n",
        "* It's calculated as the square root of the sum of the squared vector values;\n",
        "\n",
        "$||v||_2 = \\sqrt{a^2_1 + a^2_2 + a^2_3}$\n",
        "\n",
        "* It can be calculated in Numpy using the `norm()` function with default parameters;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpgTf0E2pS_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l2 = np.linalg.norm(a)\n",
        "l2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfn0-jShrvWL",
        "colab_type": "text"
      },
      "source": [
        "> Like $L^1$ norm, $L^2$ norm is often used when fitting ML algorithms as a regularization method, but is more commonly used than other vector norms in ML. For example, a method to keep the coefficients of the model small and, in turn, the model less complex.\n",
        "\n",
        "### Vector Max norm\n",
        "\n",
        "* Referred as $L^{inf}$, the notation is $||v||_{inf}$;\n",
        "\n",
        "$L^{inf}(v) = ||v||_{inf}$\n",
        "\n",
        "* It's calculated as returning the maximum value of the vector;\n",
        "\n",
        "$||v||_{inf} = \\mathrm{max}a_1,a_2,a_3$\n",
        "\n",
        "* It can be calculated in Numpy using the `norm()` function with the order parameter set to `inf`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtdl9Jm8rn6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import inf\n",
        "\n",
        "maxnorm = np.linalg.norm(a, inf)\n",
        "maxnorm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV1PK74aw5Rp",
        "colab_type": "text"
      },
      "source": [
        "> Max norm is also used as a regularization in ML, such as on NN weights, called max norm regularization.\n",
        "\n",
        "---\n",
        "\n",
        "## Chapter 9 - Matrices and matrix arithmetic\n",
        "\n",
        "* Matrix is a two-dimensional array (a table) of numbers;\n",
        "\n",
        "* The notation is often an uppercase letter, such as $A$, and entries are referred to by their two-dimensional subscript of row ($i$) and column ($j$), such as $a_{i,j}$;\n",
        "\n",
        "$A = ((a_{1,1},a_{1,2}),(a_{2,1},a_{2,2}),(a_{3,1},a_{3,2}))$\n",
        "\n",
        "* Often the dimensions of the matrix are denoted as $m$ and $n$ or $m \\times n$ for the number of rows and the number of columns respectively.\n",
        "\n",
        "### Defining a matrix\n",
        "\n",
        "* In python we can represent a matrix using a two-dimensional Numpy array.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jmZL7wSwtlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx2ichD79xu9",
        "colab_type": "text"
      },
      "source": [
        "### Matrix arithmetic\n",
        "\n",
        "* Some operations are performed element-wise between two matrices of equal size to result in a new matrix with the same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcvascXb9kZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define first matrix\n",
        "A = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "print(A)\n",
        "# Define second matrix\n",
        "B = np.array([[0.5, 0.5, 0.5],\n",
        "              [0.5, 0.5, 0.5]])\n",
        "print(B)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbLjQT0v-YKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Matrix addition\n",
        "C = A + B\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txhpjhcq9ivX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Matrix subtraction\n",
        "D = A - B\n",
        "print(D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiDhz8IQ-ULc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Matrix multiplication (Hadamard product)\n",
        "E = A * B\n",
        "print(E)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PEwpgaF-3_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Matrix division\n",
        "F = A / B\n",
        "print(F)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3tpiNqY-_YN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Matrix-matrix multiplication (matrix dot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abeOw7w9_NKx",
        "colab_type": "text"
      },
      "source": [
        "* In matrix-matrix multiplication, the number of columns ($n$) in the first matrix ($A$) must be equal the number of rows ($m$) in the second matrix ($B$)\n",
        "\n",
        "$C(m,k) = A(m,n) \\cdot B(n,k)$\n",
        "\n",
        "* The matrix multiplication using matrix notation\n",
        "\n",
        "$ A = \\begin{pmatrix}\n",
        "       a_{1,1} & a_{1,2} \\\\[0.3em]\n",
        "       a_{2,1} & a_{2,2} \\\\[0.3em]\n",
        "       a_{3,1} & a_{3,2} \\end{pmatrix}$\n",
        "\n",
        "$ B = \\begin{pmatrix}\n",
        "       b_{1,1} & b_{1,2} \\\\[0.3em]\n",
        "       b_{2,1} & b_{2,2} \\end{pmatrix}$\n",
        "\n",
        "$ C = \\begin{pmatrix}\n",
        "       a_{1,1} \\times b_{1,1} + a_{1,2} \\times b_{2,1},a_{1,1} \\times b_{1,2} + a_{1,2} \\times b_{2,2} \\\\\n",
        "       a_{2,1} \\times b_{1,1} + a_{2,2} \\times b_{2,1},a_{2,1} \\times b_{1,2} + a_{2,2} \\times b_{2,2} \\\\\n",
        "       a_{3,1} \\times b_{1,1} + a_{3,2} \\times b_{2,1},a_{3,1} \\times b_{1,2} + a_{3,2} \\times b_{2,2} \\\\ \\end{pmatrix}$\n",
        "       \n",
        "       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTHMdjxSCiKI",
        "colab_type": "text"
      },
      "source": [
        "* It can be implemented in Numpy using the `dot()` function or with the `@` in python3.5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zes41fDVDXuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define first matrix\n",
        "A = np.array([\n",
        "[1, 2],\n",
        "[3, 4],\n",
        "[5, 6]])\n",
        "print(A)\n",
        "# define second matrix\n",
        "B = np.array([\n",
        "[1, 2],\n",
        "[3, 4]])\n",
        "print(B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2PSl7M4Debx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multiply matrices\n",
        "C = A.dot(B)\n",
        "print(C)\n",
        "# multiply matrices with @ operator\n",
        "D = A @ B\n",
        "print(D)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blle87iEEh_4",
        "colab_type": "text"
      },
      "source": [
        "### Matrix-vector multiplication\n",
        "\n",
        "* The number of columns in the matrix must be equal the number of items in the vector;\n",
        "\n",
        "* Because the vector only has one column, the result is always a vector;\n",
        "\n",
        "$c = A \\cdot v$\n",
        "\n",
        "$ A = \\begin{pmatrix}\n",
        "       a_{1,1} & a_{1,2} \\\\[0.3em]\n",
        "       a_{2,1} & a_{2,2} \\\\[0.3em]\n",
        "       a_{3,1} & a_{3,2} \\end{pmatrix}$\n",
        "\n",
        "$ v = \\begin{pmatrix}\n",
        "       v_1 \\\\[0.3em]\n",
        "       v_2 \\end{pmatrix}$\n",
        "\n",
        "$ c = \\begin{pmatrix}\n",
        "       a_{1,1} \\times v_1 + a_{1,2} \\times v_2 \\\\\n",
        "       a_{2,1} \\times v_1 + a_{2,2} \\times v_2 \\\\\n",
        "       a_{3,1} \\times v_1 + a_{3,2} \\times v_2 \\\\ \\end{pmatrix}$\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I-oTPZjDjUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# matrix-vector multiplication\n",
        "A = np.array([\n",
        "[1, 2],\n",
        "[3, 4],\n",
        "[5, 6]])\n",
        "print(A)\n",
        "# define vector\n",
        "B = np.array([0.5, 0.5])\n",
        "print(B)\n",
        "# multiply\n",
        "C = A.dot(B)\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH5CdWRXFp5p",
        "colab_type": "text"
      },
      "source": [
        "### Matrix-scalar multiplication\n",
        "\n",
        "$C = A \\cdot b$\n",
        "\n",
        "$ A = \\begin{pmatrix}\n",
        "       a_{1,1} & a_{1,2} \\\\[0.3em]\n",
        "       a_{2,1} & a_{2,2} \\\\[0.3em]\n",
        "       a_{3,1} & a_{3,2} \\end{pmatrix}$\n",
        "\n",
        "$ c = \\begin{pmatrix}\n",
        "       a_{1,1} \\times b+ a_{1,2} \\times b \\\\\n",
        "       a_{2,1} \\times b + a_{2,2} \\times b \\\\\n",
        "       a_{3,1} \\times b + a_{3,2} \\times b \\\\ \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVyc8n4XFlsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# matrix-scalar multiplication\n",
        "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "print(A)\n",
        "# define scalar\n",
        "b = 0.5\n",
        "print(b)\n",
        "# multiply\n",
        "C = A * b\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0EmxRqsGG5K",
        "colab_type": "text"
      },
      "source": [
        "## Chapter 10 - Types of matrices\n",
        "\n",
        "### Square matrix\n",
        "\n",
        "* The number of rows($n$) is equivalent to the number of columns ($m$);\n",
        "\n",
        "> The rectangular matrix has a different the number of rows and columns.\n",
        "\n",
        "$ M = \\begin{pmatrix}\n",
        "       1 \\space 2 \\space 3 \\\\\n",
        "       1 \\space 2 \\space 3 \\\\\n",
        "       1 \\space 2 \\space 3 \\\\ \\end{pmatrix}$\n",
        "\n",
        "### Symmetric matrix\n",
        "\n",
        "* Is a type of square matrix where the top-right triangle is the same as the bottom-left triangle;\n",
        "\n",
        "$ M = \\begin{pmatrix}\n",
        "       1 \\space 2 \\space 3 \\space 4 \\space 5 \\\\\n",
        "       2 \\space 1 \\space 2 \\space 3 \\space 4 \\\\\n",
        "       3 \\space 2 \\space 1 \\space 2 \\space 3 \\\\\n",
        "       4 \\space 3 \\space 2 \\space 1 \\space 2 \\\\\n",
        "       5 \\space 4 \\space 3 \\space 2 \\space 1 \\end{pmatrix}$\n",
        "\n",
        "### Triangular matrix\n",
        "\n",
        "* Is a type of square matrix that has all values in the upper-right or lower-left of the matrix with the remaining elements filled with zero values;\n",
        "\n",
        "* Upper triangular matrix:\n",
        "\n",
        "$ M = \\begin{pmatrix}\n",
        "       1 \\space 2 \\space 3 \\\\\n",
        "       0 \\space 2 \\space 3 \\\\\n",
        "       0 \\space 0 \\space 3 \\\\ \\end{pmatrix}$\n",
        "\n",
        "* Lower triangular matrix:\n",
        "\n",
        "$ M = \\begin{pmatrix}\n",
        "       1 \\space 0 \\space 0 \\\\\n",
        "       1 \\space 2 \\space 0 \\\\\n",
        "       1 \\space 2 \\space 3 \\\\ \\end{pmatrix}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOCow2IxggY1",
        "colab_type": "text"
      },
      "source": [
        "* Numpy has a function for lower triangular matrix (`tril`) and upper triangular matrix (`triu`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSUw9Ku7GC2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "M = np.array([[1,2,3],\n",
        "              [1,2,3],\n",
        "              [1,2,3]])\n",
        "M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KMjjNYGgO4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lower triangular matrix\n",
        "lower = np.tril(M)\n",
        "print(lower)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dITsX5bvgVUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upper triangular matrix\n",
        "upper = np.triu(M)\n",
        "print(upper)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOk0N8B6gaoy",
        "colab_type": "text"
      },
      "source": [
        "### Diagonal matrix\n",
        "\n",
        "* Consist mostly of zeros and have non-zero entries only along the main diagonal;\n",
        "\n",
        "$ D = \\begin{pmatrix}\n",
        "       1 \\space 0 \\space 0 \\\\\n",
        "       0 \\space 2 \\space 0 \\\\\n",
        "       0 \\space 0 \\space 3 \\\\\n",
        "       0 \\space 0 \\space 0 \\end{pmatrix}$\n",
        "\n",
        "* As a vector:\n",
        "\n",
        "$ D = \\begin{pmatrix}\n",
        "       d_{1,1} \\\\\n",
        "       d_{2,2} \\\\\n",
        "       d_{3,3} \\\\ \\end{pmatrix}$\n",
        "\n",
        "* Numpy provides the function *diag()* that can create a diagonal matrix from a existing matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4IjwIO7gYAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = np.diag(M)\n",
        "print(d)\n",
        "D = np.diag(d)\n",
        "print(D)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0J5KXS8j8JT",
        "colab_type": "text"
      },
      "source": [
        "### Identity matrix\n",
        "\n",
        "* Is a square that does not change a vector when multiplied;\n",
        "\n",
        "* All of the scalar values along the main diagonal (top-left to bottom-right) have the value one, while all other values are zero;\n",
        "\n",
        "$ I = \\begin{pmatrix}\n",
        "       1 \\space 0 \\space 0 \\\\\n",
        "       0 \\space 1 \\space 0 \\\\\n",
        "       0 \\space 0 \\space 1 \\\\ \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLLLXQ_tmz24",
        "colab_type": "text"
      },
      "source": [
        "* In Numpy we can use the `identity()` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-EP8p3rjvYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "I = np.identity(3)\n",
        "I"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6knceyIm-J6",
        "colab_type": "text"
      },
      "source": [
        "### Orthogonal matrix\n",
        "\n",
        "* Two vectors are orthogonal when their dot product is equals zero;\n",
        "\n",
        "* The length of each vector is 1 then the vectors are called orthonormal because they are both orthogonal and normalized;\n",
        "\n",
        "$v \\cdot w = 0$ or $v \\cdot w^T=0$\n",
        "\n",
        "* An orthogonal matrix is a type of square matrix whose columns and rows are orthonormal unit vectors;\n",
        "\n",
        "> Perpendicular and have a length or magnitude of 1;\n",
        "\n",
        "* The Orthogonal matrix is defined formally as:\n",
        "\n",
        "$Q^T \\cdot Q = Q \\cdot Q^T = I$\n",
        "\n",
        "> $Q$ is the orthogonal matrix, $Q^T$ is the transpose of $Q$, and $I$ is the identity matrix.\n",
        "\n",
        "* A matrix is orthogonal if its transpose is equal to its inverse;\n",
        "\n",
        "$Q^T = Q^{-1}$\n",
        "\n",
        "* And if the dot product of the matrix and itself are equals the identity matrix;\n",
        "\n",
        "$Q \\cdot Q^T = I$\n",
        "\n",
        "* Orthogonal matrices are used a lot for linear transformations, such as **reflections and permutations**;\n",
        "\n",
        "* A simple 2x2 orthogonal matrix (reflection matrix or coordinate reflection):\n",
        "\n",
        "$ Q = \\begin{pmatrix}\n",
        "       1 \\space 0 \\\\\n",
        "       0 \\space -1 \\end{pmatrix}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVbl3T7PpbyX",
        "colab_type": "text"
      },
      "source": [
        "* With Numpy we can create a orthogonal matrix and check the equivalences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRL3Tl-Wm8sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = np.array([[1,0],\n",
        "              [0,-1]])\n",
        "print(Q)\n",
        "# Inverse equivalence\n",
        "V = np.linalg.inv(Q)\n",
        "print(Q.T)\n",
        "print(V)\n",
        "# Identity equivalence\n",
        "I = Q.dot(Q.T)\n",
        "print(I)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf6_o_o6qIBi",
        "colab_type": "text"
      },
      "source": [
        "* Sometimes a number close to zero can be represented as $-0$ due to the rounding of floating point precision, just take it as $0.0$;\n",
        "\n",
        "* Orthogonal matrices are useful tools as they are computanionally cheap and stable to calculate their inverse as simply their transpose.\n",
        "\n",
        "---\n",
        "\n",
        "## Chapter 11 - Matrix operations\n",
        "\n",
        "### Transpose\n",
        "\n",
        "* A matrix can be transposed, which creates a new matrix with the number of columns and rows flipped;\n",
        "\n",
        "$C = A^T$\n",
        "\n",
        "$ A = \\begin{pmatrix}\n",
        "       1 \\space 2 \\\\\n",
        "       3 \\space 4 \\\\\n",
        "       5 \\space 6 \\\\ \\end{pmatrix}$\n",
        "\n",
        "$ A^T = \\begin{pmatrix}\n",
        "       1 \\space 3 \\space 5 \\\\\n",
        "       2 \\space 4 \\space 6 \\end{pmatrix}$\n",
        "\n",
        "* We can transpose a matrix in Numpy using the **T** attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvhFbB4Dp6J_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = np.array([\n",
        "[1, 2],\n",
        "[3, 4],\n",
        "[5, 6]])\n",
        "print(A)\n",
        "# calculate transpose\n",
        "C = A.T\n",
        "print(C)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ujznMujrp69",
        "colab_type": "text"
      },
      "source": [
        "## Inverse\n",
        "\n",
        "* Matrix inversion is a process that finds another matrix that when multiplied with the matrix, results in an identity matrix;\n",
        "\n",
        "$AB = BA = I^n$\n",
        "\n",
        "* The operation of iverting a matrix is indicated by a $-1$ superscript next to the matrix:\n",
        "\n",
        "$B = A^{-1}$\n",
        "\n",
        "* A matrix can be inverted in Numpy using the `inv` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVpTOpf5q_Xi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = np.array([[1.0, 2.0],\n",
        "              [3.0, 4.0]])\n",
        "print(A)\n",
        "B = np.linalg.inv(A)\n",
        "print(B)\n",
        "I = A.dot(B)\n",
        "print(I)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f88YVn7Suyqj",
        "colab_type": "text"
      },
      "source": [
        "* Matrix inversion is used as an operation in solving systems of equations framed as matrix equations where we are interested in finding vectors of unknows;\n",
        "\n",
        "* A good example is in finding the vector of coefficient values in linear regression.\n",
        "\n",
        "### Trace\n",
        "\n",
        "* Is the sum of the values on the main diagonal of the matrix (top-left to bottom-right);\n",
        "\n",
        "* Alone, the trace operation is not interesting, but it offers a simpler notation and it is used as an element in other key matrix operations;\n",
        "\n",
        "* Is described as the notation $tr(A)$:\n",
        "\n",
        "$tr(A) = a_{1,1} + a_{2,2} + a_{3,3}$\n",
        "\n",
        "* In Numpy we use the `trace()` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpbYSmqQuReQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = np.array([\n",
        "[1, 2, 3],\n",
        "[4, 5, 6],\n",
        "[7, 8, 9]])\n",
        "print(A)\n",
        "# calculate trace\n",
        "B = np.trace(A)\n",
        "print(B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoOb3M7sweb6",
        "colab_type": "text"
      },
      "source": [
        "## Determinant\n",
        "\n",
        "* Is a scalar representation of the volume of the matrix;\n",
        "\n",
        "* Denoted by the $det(A)$ or $|A|$;\n",
        "\n",
        "* Is the product of all the **eigenvalues** of the matrix;\n",
        "\n",
        "* It describes the way a matrix will scale another matrix when they are multiplied together;\n",
        "\n",
        "> A determinant of 1 preserves the space of the other matrix, a determinant of 0 indicates that the matrix cannot be inverted.\n",
        "\n",
        "* Like the **trace** operation, alone it is not interesting, but it offers a simpler notation and it is used as an element in other key matrix operations;\n",
        "\n",
        "* In Numpy we use the `det()` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XZ_ejaiv7S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = np.array([\n",
        "[1, 2, 3],\n",
        "[4, 5, 6],\n",
        "[7, 8, 9]])\n",
        "print(A)\n",
        "# calculate determinant\n",
        "B = np.linalg.det(A)\n",
        "print(B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nLVFt943Biy",
        "colab_type": "text"
      },
      "source": [
        "## Rank\n",
        "\n",
        "* The rank of a matrix is the estimate of the number of linearly independent rows or columns in a matrix;\n",
        "\n",
        "* Denoted as $rank(A)$;\n",
        "\n",
        "* An intuition for **rank** is to consider it the number of dimensions spanned by all of the vectors within a matrix;\n",
        "\n",
        "> A **rank** of 0 suggest all vectors span a point, a **rank** of 1 suggests all vectors span a line, a rank of 2 suggest all vectors span a two-dimensional plan.\n",
        "\n",
        "* It is estimated numerically, often using a matrix decomposition method. A common approach is to use the Singular-Value Decomposition (SVD);\n",
        "\n",
        "* Numpy provides the `matrix_rank()` function, it used the SVD method to estimate the rank."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaBo7XKU2q-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rank\n",
        "v1 = np.array([1,2,3])\n",
        "print(v1)\n",
        "vr1 = np.linalg.matrix_rank(v1)\n",
        "print(vr1)\n",
        "print()\n",
        "# zero rank\n",
        "v2 = np.array([0,0,0,0,0])\n",
        "print(v2)\n",
        "vr2 = np.linalg.matrix_rank(v2)\n",
        "print(vr2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsajEe1K5aGL",
        "colab_type": "text"
      },
      "source": [
        "* The next example makes it clear that the **rank** isn't the number of dimensions of the matrix, but the number of linearly independent directions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTHd32Pf3td-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rank 0\n",
        "M0 = np.array([\n",
        "[0,0],\n",
        "[0,0]])\n",
        "print(M0)\n",
        "mr0 = np.linalg.matrix_rank(M0)\n",
        "print(mr0)\n",
        "print()\n",
        "\n",
        "# rank 1\n",
        "M1 = np.array([\n",
        "[1,2],\n",
        "[1,2]])\n",
        "print(M1)\n",
        "mr1 = np.linalg.matrix_rank(M1)\n",
        "print(mr1)\n",
        "print()\n",
        "\n",
        "# rank 2\n",
        "M2 = np.array([\n",
        "[1,2],\n",
        "[3,4]])\n",
        "print(M2)\n",
        "mr2 = np.linalg.matrix_rank(M2)\n",
        "print(mr2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdMdyFTG6IPI",
        "colab_type": "text"
      },
      "source": [
        "## Chapter 12 - Sparse matrices\n",
        "\n",
        "* Matrices that *contain mostly zero values* are called **sparse**, distinct from matrices where most of the values are non-zero, called **dense**;\n",
        "\n",
        "* Improvement in performance can be achieved by using representations and operations that specifically handle the matrix sparsity;\n",
        "\n",
        "### Sparce matrix\n",
        "\n",
        "* The sparsity of a matrix can be quantified with a score, which is the number of zero values in the matrix divided by the total number of elements in the matrix;\n",
        "\n",
        "$sparcity = \\frac{count \\space of \\space non-zero \\space elements}{total \\space elements}$\n",
        "\n",
        "$ A = \\begin{pmatrix}\n",
        "       1 \\space 0 \\space 0 \\space 1 \\space 0 \\space 0 \\\\\n",
        "       0 \\space 0 \\space 2 \\space 0 \\space 0 \\space 1 \\\\\n",
        "       0 \\space 0 \\space 0 \\space 2 \\space 0 \\space 0 \\\\ \\end{pmatrix}$\n",
        "\n",
        "> The example has 13 zero values of the 18 elements in the matrix, giving this matrix a sparsity score of 0.722 or about 72%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3Do_kwJLw2S",
        "colab_type": "text"
      },
      "source": [
        "#### a) space complexity\n",
        "\n",
        "* Very large matrices require a lot of memory, and some very large matrices that we wish to work with are sparse.\n",
        "\n",
        "#### b) time complexity\n",
        "\n",
        "* Performe operations across this matrix may take a long time where the bulk of the computation performed will involve adding or multiplying zero values together;\n",
        "\n",
        "### Sparce matrix in ML\n",
        "\n",
        "#### a) data\n",
        "\n",
        "* Sparce matrices come up in some specific types of data, most notably observations that record the occurrence or count of an activity.\n",
        "\n",
        "#### b) data preparation\n",
        "\n",
        "* Sparce matrices come up in encoding shemes used in the data preparation.\n",
        "\n",
        "> One hot encoding, count encoding, TF-IDF encoding.\n",
        "\n",
        "#### c) areas of study\n",
        "\n",
        "* Some areas of study within ML must develop specialized methods to address sparsity directly as the input data is almost always sparse.\n",
        "\n",
        "> Natural language processing, recommender systems, computer vision.\n",
        "\n",
        "### Working with sparce matrices\n",
        "\n",
        "* To work and represent sparce matrices we use a alternate structure where the zero values can be ignored and only the data or non-zero values need to be stored or acted upon.\n",
        "\n",
        " * **Dictionary of keys** : where a row and column index is mapped to a value;\n",
        "\n",
        " * **List of lists**: each row of the matrix is stored as a list, with each sublist containing the column index and the value;\n",
        "\n",
        " * **Coordinate list**: a list of tuples is stored with each tuple containing the row index, column index, and the value.\n",
        "\n",
        "* There are data structures that are more suitable for performing efficient operations:\n",
        "\n",
        " * **Compressed sparse row (CSR)**: three one-dimensional arrays for the non-zero values, the extents of the rows, and the column indexes. *Commonly used in ML*;\n",
        "\n",
        " * **Compressed sparse column**: the same as the *compressed sparce row* method except the column indices are compressed and read first before the row indices.\n",
        "\n",
        "### Sparce matrices in python\n",
        "\n",
        "* A dense matrix stored in a numpy array can be converted into a sparse matrix using the CSR representation by calling the `csr_matrix()` function;\n",
        "\n",
        "* In the example below, we define a 3x6 sparse matrix as a dense array, convert it to a CSR sparse represetation, and then convert it back to a dense array by calling the `todense()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLlmhySw5_If",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "A = np.array([[1,0,0,1,0,0],\n",
        "              [0,0,2,0,0,1],\n",
        "              [0,0,0,2,0,0]])\n",
        "print(A)\n",
        "\n",
        "# convert to sparse matrix (CSR method)\n",
        "S = csr_matrix(A)\n",
        "print()\n",
        "print(S)\n",
        "\n",
        "# reconstruct dense matrix\n",
        "B = S.todense()\n",
        "print()\n",
        "print(B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RWQoT6UCuD9",
        "colab_type": "text"
      },
      "source": [
        "* Numpy does not provide a function to calculate the sparsity of a matrix. Nevertheless, we can calculatr it finding the density of the matrix and subtracting it from one;\n",
        "\n",
        "* The number of non-zero elements can be given by the `count_nonzero()` function and the total number of elements in the array can be given bu the size property of the array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lJuawBGB9DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sparsity = 1.0 - np.count_nonzero(A) / A.size\n",
        "print(sparsity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSfxQgbdDdNl",
        "colab_type": "text"
      },
      "source": [
        "## Chapter 13 - Tensor and tensor arithmetic\n",
        "\n",
        "### What are tensors\n",
        "\n",
        "* Is a generalization of vectors and matrices and is easily understood as a multidimensional array;\n",
        "\n",
        "* A vector is a one-dimensional or first order tensor and a matrix is a two-dimensional or second order tensor;\n",
        "\n",
        "* Below defines a $3 \\times 3 \\times 3$ three-dimensional tensor $T$ with dimensions index as $t_{i,j,k}$:\n",
        "\n",
        "$ A = \\begin{pmatrix}\n",
        "       t_{1,1,1} \\space t_{1,2,1} \\space t_{1,3,1} \\\\\n",
        "       t_{2,1,1} \\space t_{2,2,1} \\space t_{2,3,1} \\\\\n",
        "       t_{3,1,1} \\space t_{3,2,1} \\space t_{3,3,1} \\end{pmatrix} , \\begin{pmatrix}\n",
        "       t_{1,1,2} \\space t_{1,2,2} \\space t_{1,3,2} \\\\\n",
        "       t_{2,1,2} \\space t_{2,2,2} \\space t_{2,3,2} \\\\\n",
        "       t_{3,1,2} \\space t_{3,2,2} \\space t_{3,3,2} \\end{pmatrix}, \\begin{pmatrix}\n",
        "       t_{1,1,3} \\space t_{1,2,3} \\space t_{1,3,3} \\\\\n",
        "       t_{2,1,3} \\space t_{2,2,3} \\space t_{2,3,3} \\\\\n",
        "       t_{3,1,3} \\space t_{3,2,3} \\space t_{3,3,3} \\end{pmatrix}$\n",
        "\n",
        "* Many of the operations that can be performed with *scalars*, *vectors*, and *matrices* can be reformulated to be performed with tensors.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elgjjOnLNr6P",
        "colab_type": "text"
      },
      "source": [
        "### Tensors in python\n",
        "\n",
        "* A tensor can be defined in-line to be a constructor of `array()` as a list of lists;\n",
        "\n",
        "* We first define rows, then a list of rows stacked as columns, then a list of column stacked as levels in a cube."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA4f44fzDQ_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a tensor\n",
        "T = np.array([\n",
        "              [[1,2,3], [4,5,6], [7,8,9]],\n",
        "              [[11,12,13], [14,15,16], [17,18,19]],\n",
        "              [[21,22,23], [24,25,26], [27,28,29]]\n",
        "])\n",
        "print(T.shape)\n",
        "print(T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcXK5xJYOhOz",
        "colab_type": "text"
      },
      "source": [
        "### Tensor arithmetic\n",
        "\n",
        "#### a) tensor addition\n",
        "\n",
        "* The element-wise addition of two tensors with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise addition of the scalars in the parent tensors.\n",
        "\n",
        "$C = A+B$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Sc2AVmOVpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define first tensor\n",
        "A = np.array([\n",
        "[[1,2,3], [4,5,6], [7,8,9]],\n",
        "[[11,12,13], [14,15,16], [17,18,19]],\n",
        "[[21,22,23], [24,25,26], [27,28,29]]])\n",
        "# define second tensor\n",
        "B = np.array([\n",
        "[[1,2,3], [4,5,6], [7,8,9]],\n",
        "[[11,12,13], [14,15,16], [17,18,19]],\n",
        "[[21,22,23], [24,25,26], [27,28,29]]])\n",
        "# add tensors\n",
        "C = A + B\n",
        "print(\"A = \", A)\n",
        "print()\n",
        "print(\"B = \", B)\n",
        "print()\n",
        "print(\"C = \", C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOPIW0ILPfZ6",
        "colab_type": "text"
      },
      "source": [
        "#### b) tensor subtraction\n",
        "* The element-wise substraction of one tensor from another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise subtraction of the scalars in the parent tensors.\n",
        "\n",
        "$C = A-B$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0jIcutiPP5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subtract tensors\n",
        "C = A - B\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV7fC4MYQAWP",
        "colab_type": "text"
      },
      "source": [
        "#### c) tensor Hadamard product\n",
        "\n",
        "* The element-wise multiplication of one tensor with another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise multiplication of the scalars in the parent tensors;\n",
        "\n",
        "* The Hadamard product is different from tensor multiplication (product), and it is represented by the operator $\\circ$\n",
        "\n",
        "$C = A \\circ B$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq6SSbKQP7id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multiply tensors\n",
        "C = A * B\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53UCuQnLRSYB",
        "colab_type": "text"
      },
      "source": [
        "#### d) tensor division\n",
        "\n",
        "* The element-wise division of one tensor with another tensor with the same dimensions results in a new tensor with the same dimensions where each scalar value is the element-wise division of the scalars in the parent tensors;\n",
        "\n",
        "$C = \\frac{A}{B}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSU42skURDcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# divide tensors\n",
        "C = A / B\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UgBYPqHR5Cp",
        "colab_type": "text"
      },
      "source": [
        "#### e) tensor product\n",
        "\n",
        "* Given a tensor $A$ with $q$ dimensions and tensor $B$ with $r$ dimensions, the product of theses tensors will be a new tensor with the order of $q + r$ dimensions;\n",
        "\n",
        "$C = A \\otimes B$\n",
        "\n",
        "$ A = \\begin{pmatrix}\n",
        "       a_{1,1} \\space a_{1,2} \\\\\n",
        "       a_{2,1} \\space a_{2,2} \\end{pmatrix}$\n",
        "\n",
        "$ B = \\begin{pmatrix}\n",
        "       b_{1,1} \\space b_{1,2} \\\\\n",
        "       b_{2,1} \\space b_{2,2} \\end{pmatrix}$\n",
        "\n",
        "$ C = \\begin{pmatrix}\n",
        "       a_{1,1} \\times b_{1,1} \\space a_{1,1} \\times b_{1,2} \\space a_{1,2} \\times b_{1,1} \\space a_{1,2} \\times b_{1,2} \\\\\n",
        "       a_{1,1} \\times b_{2,1} \\space a_{1,1} \\times b_{2,2} \\space a_{1,2} \\times b_{2,1} \\space a_{1,2} \\times b_{2,2} \\\\\n",
        "       a_{2,1} \\times b_{1,1} \\space a_{2,1} \\times b_{1,2} \\space a_{2,2} \\times b_{1,1} \\space a_{2,2} \\times b_{1,2} \\\\ a_{2,1} \\times b_{2,1} \\space a_{2,1} \\times b_{2,2} \\space a_{2,2} \\times b_{2,1} \\space a_{2,2} \\times b_{2,2} \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "224oDw-aUpya",
        "colab_type": "text"
      },
      "source": [
        "* The tensor product in numpy is the `tensordot()` function. The function takes as arguments the two tensors to be multiplied and the axis on which to sum the products over (*sum reduction*);\n",
        "\n",
        "* To calculate the tensor product (tensor dot product in numpy), the axis must be set to 0;\n",
        "\n",
        "* In the example, we define two order-1 tensors (vectors) with and calculate the tensor product:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_6oO0LnR2fQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define first vector\n",
        "A = np.array([1,2])\n",
        "# define second vector\n",
        "B = np.array([3,4])\n",
        "# calculate tensor product\n",
        "C = np.tensordot(A, B, axes=0)\n",
        "print(C)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx6u2e_HVfLP",
        "colab_type": "text"
      },
      "source": [
        "* The tensor product is the most common form of tensor multiplication, but there are many other types of tensor multiplications that exist, such as the **tensor dot product** and the **tensor contraction**.\n",
        "\n",
        "---\n",
        "\n",
        "## Chapter 14 - Matrix decomposition\n",
        "\n",
        "* Also call **matrix factorization methods**, are methods that reduce a matrix into constituent parts that make it easier to calculate more complex matrix operations;\n",
        "> It's a way of reducing a matrix into its constituent parts.\n",
        "\n",
        "* There a range of different matrix decomposition techniques:\n",
        "\n",
        "### 1. LU decomposition\n",
        "\n",
        "* It's for square matrices and decomposes a matrix into $L$ and $U$ components;\n",
        "\n",
        "$A = L \\cdot U$\n",
        "\n",
        "> Where $A$ is the square matrix that we wish to decompose, $L$ is the lower triangle matrix and $U$ is the upper triangle matrix.\n",
        "\n",
        "* The LU decomposition is found using an iterative numerical process and can fail for those matrices that cannot be decomposed or decomposed easily;\n",
        "\n",
        "* A variation of this decomposition is numerically more stable to solve in practice is call LU decomposition with partial pivoting (LUP);\n",
        "\n",
        "$A = L \\cdot U \\cdot P$\n",
        "\n",
        "* The rows of the parent matrix are re-ordered to simplify the decomposition process and the additional P matrix specifies a way to permute the result or return the result to the original order;\n",
        "\n",
        "* The LU decomposition is often used to simplify the solving of systems of linear equations;\n",
        "> e.g.: Finding the coefficients in a linear regression, as well as in calculation the determinant and inverse of a matrix.\n",
        "\n",
        "* The LU decomposition can be implemented in Python with the `lu()` function, this function calculates an LPU decomposition.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jrf_YvrEVYHC",
        "colab_type": "code",
        "outputId": "ac947eb8-e0d5-4ccd-e554-551b0772d0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "import scipy\n",
        "# LUP decomposition\n",
        "A = np.array([\n",
        "[1, 2, 3],\n",
        "[4, 5, 6],\n",
        "[7, 8, 9]])\n",
        "\n",
        "# Factorize\n",
        "P,L,U = scipy.linalg.lu(A)\n",
        "print(P)\n",
        "print(L)\n",
        "print(U)\n",
        "print()\n",
        "# Reconstruct\n",
        "B = P.dot(L).dot(U)\n",
        "print(B)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n",
            "[[1.         0.         0.        ]\n",
            " [0.14285714 1.         0.        ]\n",
            " [0.57142857 0.5        1.        ]]\n",
            "[[7.         8.         9.        ]\n",
            " [0.         0.85714286 1.71428571]\n",
            " [0.         0.         0.        ]]\n",
            "\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]\n",
            " [7. 8. 9.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83w99uOvkivk",
        "colab_type": "text"
      },
      "source": [
        "### 2. QR decomposition\n",
        "\n",
        "* Is for $n \\times m$ matrices (not limited to square matrices) and decomposes a matrix into $Q$ and $R$ components;\n",
        "\n",
        "$A = Q \\cdot R$\n",
        "\n",
        "> Where $A$ is the matrix that we wish to decompose, $Q$ a matrix with the size $m\\times m$, and $R$ is an upper triangle matrix with the size $m \\times n$.\n",
        "\n",
        "* QR decomposition is found using an iterative numerical method that can fail for those matrices that cannot be decomposed, or decomposed easily. Like the LU decomposition, it is often used to solve systems of linear equations, although is not limited to square matrices;\n",
        "\n",
        "* It can be implemented in Numpy using the `qr()` function, by default the fuction returns the $Q$ and $R$ matrices with smaller or reduced dimensions that is more economical. We can change this to return the expected sizes of $m \\times m$ for $Q$ and $m \\times n$ for $R$ by specifying the mode argument as `complete`, but not required for most applications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJGvcf7qjopt",
        "colab_type": "code",
        "outputId": "b5c7a095-9ceb-4e61-abc8-a7aed80a5be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "# QR decomposition\n",
        "A = np.array([\n",
        "[1, 2],\n",
        "[3, 4],\n",
        "[5, 6]])\n",
        "\n",
        "# Factorize\n",
        "Q, R = np.linalg.qr(A, \"complete\")\n",
        "print(Q)\n",
        "print(R)\n",
        "print()\n",
        "\n",
        "# Reconstruct\n",
        "B = Q.dot(R)\n",
        "print(B)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.16903085  0.89708523  0.40824829]\n",
            " [-0.50709255  0.27602622 -0.81649658]\n",
            " [-0.84515425 -0.34503278  0.40824829]]\n",
            "[[-5.91607978 -7.43735744]\n",
            " [ 0.          0.82807867]\n",
            " [ 0.          0.        ]]\n",
            "\n",
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJzfO8lvoLgu",
        "colab_type": "text"
      },
      "source": [
        "### 3. Cholesky decomposition\n",
        "\n",
        "* It's for square symmetric matrices where all values are greater than zero, so-called **positive definite matrices**;\n",
        "> We'll focus on the Cholesky decomposition for real-valued matrices and ignore the cases when working with complex numbers.\n",
        "\n",
        "$A = L \\cdot L^T$\n",
        "\n",
        "> Where $A$ is the matrix being decomposed, $L$ is the lower triangular matrix and $L^T$ is the transpose of $L$.\n",
        "\n",
        "* The decompose can also be written as the product of the upper triangular matrix:\n",
        "\n",
        "$A = U^T \\cdot U$\n",
        "\n",
        "> Where $U$ is the upper triangular matrix.\n",
        "\n",
        "* The Cholesky decomposition is used for solving linear least squares for linear regression, as well as simulation and optimization methods;\n",
        "\n",
        "* When decomposing symmetric matrices, the Cholesky decomposition is nearly twice as efficient as the LU decomposition and should be preferred in these cases;\n",
        "\n",
        "* In Numpy we can use the `cholesky()` function, it returns $L$ as we can easily access the $L$ transpose as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6lWyn2OoC0b",
        "colab_type": "code",
        "outputId": "ee1a7aea-3c75-4ff1-9c22-62d2b72db5bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# Cholesky decomposition\n",
        "A = np.array([\n",
        "[2, 1, 1],\n",
        "[1, 2, 1],\n",
        "[1, 1, 2]])\n",
        "\n",
        "# Factorize\n",
        "L = np.linalg.cholesky(A)\n",
        "print(L)\n",
        "print()\n",
        "\n",
        "# Reconstruct\n",
        "B = L.dot(L.T)\n",
        "print(B)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.41421356 0.         0.        ]\n",
            " [0.70710678 1.22474487 0.        ]\n",
            " [0.70710678 0.40824829 1.15470054]]\n",
            "\n",
            "[[2. 1. 1.]\n",
            " [1. 2. 1.]\n",
            " [1. 1. 2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtW3VlspqlNX",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Chapter 15 - Eigendecomposition\n",
        "\n",
        "* It decomposes a matrix into eigenvectors and eigenvalues;\n",
        "> Uder in the principal component analysis (PCA) method.\n",
        "\n",
        "### Eigendecomposition of a matrix\n",
        "\n",
        "* Involves decomposing a square matrix into a set of eigenvectors and eigenvalues;\n",
        "\n",
        "* A vector is an eigenvector of a matrix if it satisfies the eigenvalue equation:\n",
        "\n",
        "$A.v = \\lambda.v$\n",
        "\n",
        "> Where $A$ is the parent square matrix that we're decomposing, $v$ is the eigenvector of the matrix, and $\\lambda$ represents the eigenvalue scalar.\n",
        "\n",
        "* A matrix could have one eigenvector and eigenvalue for each dimension of the parent matrix;\n",
        "\n",
        "* Not all square matrices can be decomposed into eigenvectors and eigenvalues, and some can only be decomposed in a way that requires complex numbers;\n",
        "\n",
        "* The parent matrix can be show to be a product of the eigenvectors and eigenvalues;\n",
        "\n",
        "$A = Q.\\Lambda.Q^T$\n",
        "\n",
        "> Where $Q$ is a matrix comprised of the eigenvectors, $\\Lambda$ is the diagonal matrix comprised of the eigenvalues, and $Q^T$ is the transpose of the matrix comprises of the eigenvectors.\n",
        "\n",
        "* A decomposition operation does not result in a compression of the matrix. Instead, it breaks it down into constituent parts to make certain operations on the matrix easier to perform;\n",
        "\n",
        "* Eigendecomposition is used as an element to simpligy the calculation of other more complex matrix operations;\n",
        "\n",
        "* Almost all vectors change direction, when they are multiplied by $A$. Certain exceptional vectors $x$ are in the same direction as $Ax$. Those are the \"eigenvectors\";\n",
        "\n",
        "* Multiply an eigenvector by $A$, and the vector $Ax$ is the number $\\lambda$ times the original $x$;\n",
        "\n",
        "* The eigenvalue $\\lambda$ tells whether the special vector $x$ is stretched or shrunk or reversed or left unchanged, when it is multiplied by $A$.\n",
        "\n",
        "### Eigenvectors and eigenvalues\n",
        "\n",
        "* Eigenvectors (right vectors) are unit vectors, which means that their length or magnitude is equal to 1.0;\n",
        "\n",
        "* Eigenvalues are coeficients applied to eigenvectors that give the vectors their length or magnitude;\n",
        "> For example, a negative eigenvalue may reverse the direction of the eigenvector as part of scaling it.\n",
        "\n",
        "* A matrix that has only positive eigenvalues is referred to as a **positive definite matrix**, whereas if the eigenvalues are all negative, it is referred to as a **negative definite matrix**.\n",
        "\n",
        "### Calculation of eigendecomposition\n",
        "\n",
        "* An eigendecomposition is calculated on a square matrix using an efficient iterative algorithm;\n",
        "\n",
        "* Often an eigenvalue is found first, then an eigenvector is found to solve the equation as a set of coefficients;\n",
        "\n",
        "* The eigendecomposition can be calculated in NumPy using the `eig()`function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dOrWfaAqbh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "8d5455a3-b0c6-4e71-835f-d762e90b6823"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# eigendecomposition\n",
        "A = np.array([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]])\n",
        "print(A)\n",
        "print()\n",
        "\n",
        "# factorize\n",
        "values, vectors = np.linalg.eig(A)\n",
        "print(values)\n",
        "print(vectors)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "\n",
            "[ 1.61168440e+01 -1.11684397e+00 -1.30367773e-15]\n",
            "[[-0.23197069 -0.78583024  0.40824829]\n",
            " [-0.52532209 -0.08675134 -0.81649658]\n",
            " [-0.8186735   0.61232756  0.40824829]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RY-eld0aOB",
        "colab_type": "text"
      },
      "source": [
        "### Confirm an eigenvector and eigenvalue\n",
        "\n",
        "* To confirm that a vector is a eigenvector we multiply it by the value and comparing the result with the eigenvalue;\n",
        "\n",
        "* Define a matrix, then calculate the eigenvalues and eigenvectors, then test whether the first vector and value are in fact an eigenvalue and eigenvector for the matrix;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chIykjY60XpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b43125bb-c4ba-47f8-ddcd-9d0c69c89f0b"
      },
      "source": [
        "B = A.dot(vectors[:, 0])\n",
        "print(B)\n",
        "print()\n",
        "\n",
        "C = vectors[:, 0] * values[0]\n",
        "print(C)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ -3.73863537  -8.46653421 -13.19443305]\n",
            "\n",
            "[ -3.73863537  -8.46653421 -13.19443305]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca3XuOFe0eHY",
        "colab_type": "text"
      },
      "source": [
        "* The eigenvectors are returned as a matrix with the same dimensions as the parent matrix, where each column is an eigenvector;\n",
        "> e.g. the first eigenvector is `vector[:,0]`.\n",
        "\n",
        "* Eigenvalues are returned as a list, where value indices in the returned array are paired with eigenvectors by column index.\n",
        "> e.g. the first eigenvalue at `values[0]` is paired with the first eigenvector at `vectors[:, 0]`.\n",
        "\n",
        "* The example multiplies the original matrix with the first eigenvector and compares it to the first eigenvector multiplied by the first eigenvalue.\n",
        "\n",
        "### Reconstruct matrix\n",
        "\n",
        "* First, the list of eigenvectors must be taken together as a matrix, where each vector becomes a row;\n",
        "\n",
        "* The eigenvalues need to be arraged into a diagonal matrix (`diag()`), then we need the inverse of the eigenvector matrix (`inv()`) and finally multiply together using the `dot()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRkTwJb00b8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0eb5ce70-fd86-47fe-ab36-711681a5c8d3"
      },
      "source": [
        "# create a matrix from eigenvectors\n",
        "Q = vectors\n",
        "\n",
        "# create inverse of eigenvectors matrix\n",
        "R = np.linalg.inv(Q)\n",
        "\n",
        "# create diagonal matrix from eigenvalues\n",
        "L = np.diag(values)\n",
        "\n",
        "# reconstruct the original matrix\n",
        "B = Q.dot(L).dot(R)\n",
        "print(B)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]\n",
            " [7. 8. 9.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoOMqPx80szi",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Chapter 16 - Singular value decomposition (SVD)\n",
        "\n",
        "* All matrices have an SVD, which makes it more stable than other methods, such as the eigendecomposition;\n",
        "> It is often used in compressing, denoising, data reduction, etc.\n",
        "\n",
        "### What is the SVD\n",
        "\n",
        "* Is a matrix decomposition method for reducing a matrix to its constituent parts in order to make certain subsequent matrix calculations simpler;\n",
        "\n",
        "* Let's focus on the SVD for **real-valued matrices**, ignoring the complex numbers case;\n",
        "\n",
        "$A = U.\\Sigma.V^T$\n",
        "\n",
        "> Where $A$ is the real $n \\times m$ matrix that we wish to decompose, $U$ is an $m \\times m$ matrix, $\\Sigma$ is an $m \\times n$ diagonal matrix, and $V^T$ is the $V$ transpose of an $n \\times n$ matrix.\n",
        "\n",
        "* The diagonal values in the $\\Sigma$ matrix are known as the **singular values** of the original matrix $A$. The columns of the $U$ matrix are called the **left-singular vectors** of $A$ and the columns of $V$ are called the **right-singular vectors** of $A$;\n",
        "\n",
        "* The SVD is calculated via iterative numerical methods (without details). Every rectangular matrix has a singular value decomposition, although the resulting matrices may contain complex numbers and the limitations of floating point arithmetic may cause some matrices to fail to decompose neatly;\n",
        "\n",
        "* The SVD allows to discover some of the same kind of information as the eigendecomposition been generally applicable;\n",
        "> Examples are the calculation of matrix inverse, data reduction, least squares linear regression, imag compression, and denoising data.\n",
        "\n",
        "### Calculate SVD\n",
        "\n",
        "* In NumPy the `svd()` function takes a matrix and returns the $U$, $\\Sigma$ and $V^T$ elements;\n",
        "\n",
        " - The $\\Sigma$ diagonal matrix is returned as a vector of singular values;\n",
        "\n",
        " - The $V$ matrix is returned in a transposed form ($V^T$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sxQFzG-0r5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "f80ee0c3-acd7-4add-a4f7-f149bfec0fc7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# singular-value decomposition\n",
        "A = np.array([\n",
        "    [1,2],\n",
        "    [3,4],\n",
        "    [5,6]\n",
        "])\n",
        "print(A)\n",
        "print()\n",
        "\n",
        "# factorize\n",
        "U, s, V = np.linalg.svd(A)\n",
        "print(U)\n",
        "print(s)\n",
        "print(V)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]]\n",
            "\n",
            "[[-0.2298477   0.88346102  0.40824829]\n",
            " [-0.52474482  0.24078249 -0.81649658]\n",
            " [-0.81964194 -0.40189603  0.40824829]]\n",
            "[9.52551809 0.51430058]\n",
            "[[-0.61962948 -0.78489445]\n",
            " [-0.78489445  0.61962948]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRbCoV0K00_i",
        "colab_type": "text"
      },
      "source": [
        "### Reconstruct matrix\n",
        "\n",
        "* We use the $U$, $\\Sigma$ and $V^T$ returned from `svd()` function, but they cannot be multiplied directly;\n",
        "\n",
        "* The vector `s` must be converted into a diagonal matrix (`diag()`, create a square matrix $m \\times m$ relative to the original matrix), which is a problem as the size of the matrix do not fit the rules of matrix multiplication (number tof columns in a matrix equal the number of rows of the subsequent matrix);\n",
        "\n",
        "* After creating the square $\\Sigma$ diagonal matrix, the sizes of the matrices are relative to the original $n \\times m$ matrix:\n",
        "\n",
        "$U(m \\times m) \\cdot \\Sigma(m \\times m) \\cdot V^T(n \\times n)$\n",
        "\n",
        "But we require:\n",
        "\n",
        "$U(m \\times m) \\cdot \\Sigma(m \\times n) \\cdot V^T(n \\times n)$\n",
        "\n",
        "* We can achieve this by creating a new $\\Sigma$ matrix of all zero values that is $m \\times n$ (e.g. more rows) and populate the first $n \\times n$ of the matrix with the square diagonal matrix calculated via `diag()`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHuxOOgg0ymd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3877173a-aedf-4827-ffe1-0c07eb45fdec"
      },
      "source": [
        "# reconstruct rectangular matrix from SVD\n",
        "# create m x n Sigma matrix\n",
        "sigma = np.zeros((A.shape[0], A.shape[1]))\n",
        "\n",
        "# populate Sigma with n x n diagonal matrix\n",
        "sigma[:A.shape[1], :A.shape[1]] = np.diag(s)\n",
        "\n",
        "# reconstruct matrix\n",
        "B = U.dot(sigma.dot(V))\n",
        "print(B)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsaxc3gE05Qo",
        "colab_type": "text"
      },
      "source": [
        "* The above complication with the $\\Sigma$ diagonal only exists with the case where $m$ and $n$ are different. The diagonal matrix can be used directly when reconstructing a square matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTPnjMtC03RX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "4b5335ad-5736-4b14-a62f-a0cbf2953efd"
      },
      "source": [
        "# reconstruct square matrix from SVD\n",
        "A = np.array([\n",
        "    [1,2,3],\n",
        "    [4,5,6],\n",
        "    [7,8,9]\n",
        "])\n",
        "print(A)\n",
        "print()\n",
        "\n",
        "# factorize\n",
        "U,s,V = np.linalg.svd(A)\n",
        "\n",
        "# create n x n Sigma matrix\n",
        "sigma = np.diag(s)\n",
        "\n",
        "# reconstruct matrix\n",
        "B = U.dot(sigma.dot(V))\n",
        "print(B)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]\n",
            " [7. 8. 9.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP3fwxWo0-7v",
        "colab_type": "text"
      },
      "source": [
        "### Pseudoinverse (Moore-Penrose inverse)\n",
        "\n",
        "* Is the generalization of the matrix inverse for square matrices to rectangular matrices where the number of rows and columns are not equal;\n",
        "\n",
        "$A^+ = V\\cdot D^+ \\cdot U^T$\n",
        "\n",
        "> Where $A^+$ is the pseudoinverse, $D^+$ is the pseudoinverse of the diagonal matrix $\\Sigma$ and $V^T$ is the transpose of $V^T$. We can get $U$ and $V$ from SVD operation.\n",
        "\n",
        "$A = U \\cdot \\Sigma \\cdot V^T$\n",
        "\n",
        "* The $D^+$ can be calculated by creating a diagonal matrix from $\\Sigma$, calculation the reciprocal of each non-zero element in $\\Sigma$ and taking the transpose if the original matrix was retangular;\n",
        "\n",
        "$\\Sigma = \\begin{pmatrix}\n",
        "       s_{1,1} \\space 0 \\space 0 \\\\\n",
        "       0 \\space s_{2,2} \\space 0 \\\\\n",
        "       0 \\space 0 \\space s_{3,3} \\end{pmatrix}$\n",
        "\n",
        "$D^+ = \\begin{pmatrix}\n",
        "       \\frac{1}{s_{1,1}} \\space 0 \\space 0 \\\\\n",
        "       0 \\space \\frac{1}{s_{2,2}} \\space 0 \\\\\n",
        "       0 \\space 0 \\space \\frac{1}{s_{3,3}} \\end{pmatrix}$\n",
        "\n",
        "* The pseudoinverse provides one way of solving the linear regression equation, specifically when there are more rows than columns (the often case);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8kDhHpa2dnR",
        "colab_type": "text"
      },
      "source": [
        "* NumPy provides the `pinv()` function for calculation the pseudoinverse of a rectangular matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUD6Uj7k07MH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "1253be7d-4e7a-414d-94ce-d876904a8f44"
      },
      "source": [
        "# pseudoinverse\n",
        "\n",
        "A = np.array([\n",
        "    [.1, .2],\n",
        "    [.3, .4],\n",
        "    [.5, .6],\n",
        "    [.7, .8]\n",
        "])\n",
        "print(A)\n",
        "print()\n",
        "\n",
        "# calculate pseudoinverse\n",
        "B = np.linalg.pinv(A)\n",
        "print(B)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1 0.2]\n",
            " [0.3 0.4]\n",
            " [0.5 0.6]\n",
            " [0.7 0.8]]\n",
            "\n",
            "[[-1.00000000e+01 -5.00000000e+00  1.42385628e-14  5.00000000e+00]\n",
            " [ 8.50000000e+00  4.50000000e+00  5.00000000e-01 -3.50000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XUdThM01DvJ",
        "colab_type": "text"
      },
      "source": [
        "* We can calculate the pseudoinverse manually via SVD and compare the results to the `pinv()` function;\n",
        "\n",
        "* First we must calculate the SVD, next the reciprocal of each value in the `s` array. Then the `s` array can be transformed into a diagonal matrix with an added row of zeros to make it rectangular. Finally, we can calculate the pseudoinverser from the elements:\n",
        "\n",
        "$A^+ = V^T \\cdot D^T \\cdot U^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yqKkn2L1Bck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8f0abf4d-3d81-4c13-9f9c-dd484d4d826d"
      },
      "source": [
        "# pseudoinverse via svd\n",
        "# factorize\n",
        "U,s,V = np.linalg.svd(A)\n",
        "\n",
        "# reciprocals of s\n",
        "d = 1.0 / s\n",
        "\n",
        "# create m x n D matrix\n",
        "D = np.zeros(A.shape)\n",
        "\n",
        "# populate D with n x n diagonal matrix\n",
        "D[:A.shape[1], :A.shape[1]] = np.diag(d)\n",
        "\n",
        "# calculate pseudoinverse\n",
        "B = V.T.dot(D.T).dot(U.T)\n",
        "print(B)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.00000000e+01 -5.00000000e+00  1.42578328e-14  5.00000000e+00]\n",
            " [ 8.50000000e+00  4.50000000e+00  5.00000000e-01 -3.50000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdVlLhQx1IFA",
        "colab_type": "text"
      },
      "source": [
        "### Dimensionality reduction\n",
        "\n",
        "* Data with a large number of features, such as more features (columns) than observations (row) may be reduced to a smaller subset of features that are most relevant to the prediction problem;\n",
        "\n",
        "* The result is a matrix with a lower rank that is said to approximate the original matrix;\n",
        "\n",
        "* We can perform a SVD operation on the original data and select the top %k% largest singular values in $\\Sigma$. These columns can be selected from $\\Sigma$ and the rows selected from $V^T$. An approximate $B$ of the original vector $A$ can be reconstructed;\n",
        "\n",
        "$B = U \\cdot \\Sigma_k \\cdot V_k^T$\n",
        "\n",
        "* In natural language processing (NLP), this approach can be used on matrices of word occurrences or word frequencies in documents and is called **Latent Semantic Analysis** or **Latent Semantic Indexing**.\n",
        "> In practice, we can retain and work with a descriptive subset of the data called $T$:\n",
        "\n",
        "$T = U \\cdot \\Sigma_k$\n",
        "\n",
        "* Further, this transform can be calculated and applied to the original matrix $A$ as well as other similar matrices:\n",
        "\n",
        "$T = A \\cdot V^T_k$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8fXnpy1FsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "30720dbb-8aba-4d7c-b81e-13c740b32057"
      },
      "source": [
        "# data reduction with svd\n",
        "\n",
        "A = np.array([\n",
        "    [1,2,3,4,5,6,7,8,9,10],\n",
        "    [11,12,13,14,15,16,17,18,19,20],\n",
        "    [21,22,23,24,25,26,27,28,29,30]\n",
        "])\n",
        "print(A)\n",
        "print()\n",
        "\n",
        "# factorize\n",
        "U,s,V = np.linalg.svd(A)\n",
        "\n",
        "# create m x n Sigma matrix\n",
        "sigma = np.zeros((A.shape[0], A.shape[1]))\n",
        "\n",
        "# populate Sigma with n x n diagonal matrix\n",
        "sigma[:A.shape[0], :A.shape[0]] = np.diag(s)\n",
        "\n",
        "# select\n",
        "\n",
        "n_elements = 2\n",
        "sigma = sigma[:, :n_elements]\n",
        "V = V[:n_elements, :]\n",
        "\n",
        "# reconstruct\n",
        "B = U.dot(sigma.dot(V))\n",
        "print(B)\n",
        "print()\n",
        "\n",
        "#transform\n",
        "T = U.dot(sigma)\n",
        "print(T)\n",
        "T = A.dot(V.T)\n",
        "print(T)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  2  3  4  5  6  7  8  9 10]\n",
            " [11 12 13 14 15 16 17 18 19 20]\n",
            " [21 22 23 24 25 26 27 28 29 30]]\n",
            "\n",
            "[[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
            " [11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
            " [21. 22. 23. 24. 25. 26. 27. 28. 29. 30.]]\n",
            "\n",
            "[[-18.52157747   6.47697214]\n",
            " [-49.81310011   1.91182038]\n",
            " [-81.10462276  -2.65333138]]\n",
            "[[-18.52157747   6.47697214]\n",
            " [-49.81310011   1.91182038]\n",
            " [-81.10462276  -2.65333138]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_mChny81MUW",
        "colab_type": "text"
      },
      "source": [
        "* The SVD is calculated and only the first two features are selected. The elements are recombined to give an accurate reproduction of the original matrix and the transform is calculated in two different ways;\n",
        "\n",
        "* The scikit-learn provides a `TruncatedSVD` class that implements this capability directly. This class can be created in which you must specify the number of desirable features or components to select. Once created, you can fit the transform (e.g calculate $V_k^T$) by calling `fit()` function, then apply it to the original matrix by calling the `transform()`function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZakqu831KNR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "27086987-21aa-4f82-fbf6-39f638a25dd6"
      },
      "source": [
        "# svd data reduction in scikit-learn\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# create transform\n",
        "svd = TruncatedSVD(n_components=2)\n",
        "\n",
        "# fit transform\n",
        "svd.fit(A)\n",
        "\n",
        "# apply transform\n",
        "result = svd.transform(A)\n",
        "print(result)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[18.52157747  6.47697214]\n",
            " [49.81310011  1.91182038]\n",
            " [81.10462276 -2.65333138]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1oDybTL1bXT",
        "colab_type": "text"
      },
      "source": [
        "* Except for the sign on some values, the result is the same as calculated manually above. We can expect there to be some instability when it comes to the sigh given the nature of the calculations involved and the differences in the underlying libraries and methods used.\n",
        "> This instability of sign should not be a problem in practice as long as the transform is trained to reuse.\n",
        "\n",
        "---\n",
        "\n",
        "## Part VI - Statistics\n",
        "\n",
        "### Chapter 17 - Introduction to multivariate statistics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or2MN7df1OcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}