{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 17 - Classificação e árvores de regressão\n",
    "\n",
    "* Árvores de decisão são um tipo importante de algoritmo dentro de modelos de predição em machine learning. Esse algoritmo é um clássico que é usado a décadas e variações como o *random forest* está entre uma das técnicas mais poderosas.\n",
    "\n",
    "## Representação do modelo CART\n",
    "\n",
    "* A representação para o modelo CART é uma árvore binária, onde cada nó representa uma única variável de entrada ($x$) e um ponto de separação nessa varíavel (assumindo que seja númerica). As folhas do nó da árvore contém a variável de saída ($y$) que é usada para fazer a predição.\n",
    "\n",
    "* Dado um conjunto de dados com duas entradas de altura (cm) e peso (kg) o output é o sexo variando entre masculino e feminino.\n",
    "\n",
    "![tree_ex](tree_ex.png)\n",
    "\n",
    "## Fazendo predições\n",
    "\n",
    "* Dado novos conjuntos de entrada a árvore é examinada começando pela raíz. O aprendizado em uma árvore binária é particionamento dos dados de entrada num plano. Pode-se pensar em cada variável de entrada como uma dimensão num espaço n-dimensional. A árvore de decisão divide o plano em retângulos (quando n=2 entradas) ou hiper-retângulos com mais entradas.\n",
    "\n",
    "* Novos dados são filtrados dentro da árvore e acaba se localizando em um dos retângulos, sendo esse valor de saída a predição do modelo.\n",
    "\n",
    "* Por exemplo, dado uma altura = 160 cm e peso = 65 kg:\n",
    "> 1. altura > 180 cm: Não;\n",
    "> 2. peso > 80 kg: Não;\n",
    "> 3. Então: Mulher.\n",
    "\n",
    "## Aprendendo um modelo CART pelos dados\n",
    "\n",
    "* Como dito, criar uma árvore de decisão binária é basicamente um processo de dividir um plano com os dados de entrada. Um método usado para dividir esse plano é o *binary splitting*. Esse é um procedimento númerico onde todos os valores são listados e se tenta criar diferentes pontos de divisão que são testado pela **função de custo**, divisão com menor custo é selecionada.\n",
    "\n",
    "* Para problemas em que o modelo de predição é regressão a **função de custo** que é minimizada para escolher os melhores pontos de divisão é a soma do quadrado dos erros para todo o dado de treinamento que caem num retângulo:\n",
    "\n",
    "$\\sum^{n}_{i=1}(y_i - prediction_i)^2$ (17.1)\n",
    "\n",
    "> Onde $y$ é o output para os dados de treinamento e $prediction$ é a predição do triângulo. Para classificação o função índice *Gini* () é usada para promover uma indicação do quão puro a folha do nó é (quão misturado são os dados de treinamento atribuío para cada nó)\n",
    "\n",
    "$G = \\sum^{n}_{k=1}p_k \\times (1 - p_k)$\n",
    "\n",
    "> Onde $G$ é índice *Gini* para todas as classes, $p_k$ são as proporções das intâncias de treinamento com a classe $k$ no retângulo de interesse. Um nó que tem todas as classes do mesmo tipo (classe perfeitamente pura) terá $G=0$, onde com um $G$ de 50-50 divisão de classe para uma classificação binária (máximo de impuresa) terá $G=0.5$. \n",
    "\n",
    "$G = 2 \\times p_1 \\times p_2$\n",
    "\n",
    "$G = 1 - (p_1^2 + p_2^2)$\n",
    "\n",
    "> O cálculo do índice *Gini* para cada nó é pesado pelo total de números de instância no nó vizinho. A pontuação de *Gini* para um ponto de divisão em um problema de divisão binária é calculada:\n",
    "\n",
    "$G = ((1 - (g1_1^2 + g1_2^2)) \\times \\frac{n_{g1}}{n}) \\times ((1 - (g2_1^2 + g2_2^2)) \\times \\frac{n_{g2}}{n})$\n",
    "\n",
    "> Onde $G$ é o índice de *Gini* para o ponto de divisão; $g1_1$ é a proporção da instância no grupo 1 para a classe 1; $g1_2$ para a classe 2, $g2_1$ para o grupo 2 e classe 1; $g2_2$ grupo2 classe 2, $n_{g1}$ e $n_{g2}$ são o número total de instâncias no grupo 1 e 2; $n$ é o número total de instâncias que nós estamos tentando agrupar do nó vizinho.\n",
    "\n",
    "## Critéro de parada\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
